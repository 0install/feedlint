#!/usr/bin/env python

from optparse import OptionParser
import sys, shutil, tempfile, urlparse
import urllib2, os, httplib
import logging, time
from logging import info

from zeroinstall import SafeException
from zeroinstall.injector import model, gpg, reader, namespaces

from display import checking, result, error, highlight

now = time.time()

version = '0.1'

WEEK = 60 * 60 * 24 * 7

parser = OptionParser(usage="usage: %prog [options] feed.xml")
parser.add_option("-v", "--verbose", help="more verbose output", action='count')
parser.add_option("-V", "--version", help="display version information", action='store_true')

(options, args) = parser.parse_args()

if options.version:
	print "FeedLint (zero-install) " + version
	print "Copyright (C) 2007 Thomas Leonard"
	print "This program comes with ABSOLUTELY NO WARRANTY,"
	print "to the extent permitted by law."
	print "You may redistribute copies of this program"
	print "under the terms of the GNU General Public License."
	print "For more information about these matters, see the file named COPYING."
	sys.exit(0)

if options.verbose:
	logger = logging.getLogger()
	if options.verbose == 1:
		logger.setLevel(logging.INFO)
	else:
		logger.setLevel(logging.DEBUG)

if len(args) < 1:
	parser.print_help()
	sys.exit(1)

checked = set()

try:
	to_check = [model.canonical_iface_uri(a) for a in args]
except SafeException, ex:
	if options.verbose: raise
	print >>sys.stderr, ex
	sys.exit(1)

def check_key(feed, fingerprint):
	for line in os.popen('gpg --with-colons --list-keys %s' % s.fingerprint):
		if line.startswith('pub:'):
			key_id = line.split(':')[4]
			break
	else:
		raise SafeException('Failed to find key with fingerprint %s on your keyring' % fingerprint)

	key_url = urlparse.urljoin(feed, '%s.gpg' % key_id)

	if key_url in checked:
		info("(already checked key URL %s)", key_url)
	else:
		checking("Checking key %s" % key_url)
		urllib2.urlopen(key_url).read()
		result('OK')
		checked.add(key_url)

def get_http_size(url, ttl = 1):
	assert url
	address = urlparse.urlparse(url)
	http = httplib.HTTPConnection(address.netloc, address.port or 80)
	http.request('HEAD', url)
	response = http.getresponse()
	try:
		if response.status == 200:
			return response.getheader('Content-Length')
		elif response.status in (301, 302):
			new_url = response.getheader('URI') or response.getheader('Location')
		else:
			raise SafeException("HTTP error: got status code %s" % response.status)
	finally:
		response.close()

	if ttl:
		result("Moved", 'YELLOW')
		checking("Checking new URL %s" % new_url)
		assert new_url
		return get_http_size(new_url, ttl - 1)
	else:
		raise SafeException('Too many redirections.')

def check_source(source):
	if hasattr(source, 'url'):
		checking("Checking archive %s" % source.url)
		actual_size = get_http_size(source.url)
		if actual_size is None:
			result("No Content-Length for archive; can't check", 'YELLOW')
		else:
			actual_size = int(actual_size)
			if actual_size != source.size:
				raise SafeException("Expected archive to have a size of %d, but server says it is %d",
						source.size, actual_size)
			result('OK')
	elif hasattr(source, 'steps'):
		for step in source.steps:
			check_source(step)

def check_exists(url):
	checking("Checking URL exists %s" % url)
	get_http_size(url)
	result('OK')

n_errors = 0

while to_check:
	feed = to_check.pop()
	if feed in checked:
		info("Already checked feed %s", feed)
		continue

	checked.add(feed)

	print "Checking", feed

	try:
		tmp = tempfile.TemporaryFile(prefix = 'feedlint-')
		try:
			stream = urllib2.urlopen(feed)
			shutil.copyfileobj(stream, tmp)
			data, sigs = gpg.check_stream(tmp)

			for s in sigs:
				if isinstance(s, gpg.ValidSig):
					check_key(feed, s.fingerprint)
				else:
					raise SafeException("Can't check sig: %s" % s)

			feed_tmp = tempfile.NamedTemporaryFile(prefix = 'feedlint-')
			try:
				shutil.copyfileobj(data, feed_tmp)
				feed_tmp.seek(0)
				iface = model.Interface(feed)
				reader.update(iface, feed_tmp.name)

				for f in iface.feeds:
					info("Will check feed %s", f.uri)
					to_check.append(f.uri)
			finally:
				feed_tmp.close()
		finally:
			tmp.close()

		for impl in iface.implementations.values():
			for r in impl.dependencies.values():
				if r.interface not in checked:
					info("Will check dependency %s", r)
					to_check.append(r.interface)
			if hasattr(impl, 'download_sources'):
				for source in impl.download_sources:
					check_source(source)
			stability = impl.upstream_stability or model.testing
			if stability == model.testing:
				error = None
				if not impl.released:
					error = "No release data on testing version"
				else:
					try:
						released = time.strptime(impl.released, '%Y-%m-%d')
					except ValueError, ex:
						error = "Can't parse date"
					else:
						ago = now - time.mktime(released)
						if ago < 0:
							error = 'Release data is in the future!'
						elif ago > 1 * WEEK:
							error = 'Has been Testing for more than a week'
				if error:
					print highlight("  Version %s: %s (released %s)" % (impl.get_version(), error, impl.released), 'RED')
		
		for homepage in iface.get_metadata(namespaces.XMLNS_IFACE, 'homepage'):
			check_exists(homepage.content)

		for icon in iface.get_metadata(namespaces.XMLNS_IFACE, 'icon'):
			check_exists(icon.getAttribute('href'))
				
				
	except urllib2.HTTPError, ex:
		print >>sys.stderr, ex
		n_errors += 1
	except SafeException, ex:
		if options.verbose: raise
		print >>sys.stderr, ex
		n_errors += 1

if n_errors == 0:
	print "OK"
else:
	print "\nERRORS FOUND:", n_errors
	sys.exit(1)
